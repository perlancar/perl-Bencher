#!perl

# DATE
# VERSION

use 5.010001;
use strict;
use warnings;

use Perinci::CmdLine::Any;

binmode(STDOUT, ":utf8");
Perinci::CmdLine::Any->new(
    url => '/Bencher/Backend/bencher',
    log => 1,
    pass_cmdline_object => 1,
)->run;

# ABSTRACT: A benchmark framework (CLI)
# PODNAME:

=head1 SYNOPSIS

List all scenario modules (Bencher::Scenario::*) installed locally on your
system:

 % bencher --list-scenario-modules
 % bencher -L

Run benchmark described by a scenario module:

 % bencher -m Example

Run benchmark described by a scenario file:

 % bencher -f scenario.pl

Add participants from the command-line instead of (or in addition to) those
specified in a scenario file/module:

 % bencher -p '{"fcall_template":"Bar::func(<arg>)"}'

Run module startup overhead benchmark instead of the normal benchmark:

 % bencher -m Example --module-startup

Show/dump scenario instead of running benchmark:

 % bencher -m Example --show-scenario

List participants instead of running benchmark:

 % bencher ... --list-participants
 % bencher ... --list-participants -l ;# show detail

List participating Perl modules (modules mentioned by all the participants):

 % bencher ... --list-participant-modules
 % bencher ... --list-participant-modules -l ;# show detail

List datasets instead of running benchmark:

 % bencher ... --list-datasets
 % bencher ... --list-datasets -l ;# show detail

List items instead of running benchmark:

 % bencher ... --list-items
 % bencher ... --list-items -l ;# show detail

Show items' codes instead of running benchmark:

 % bencher ... --show-items-codes

Show items' results instead of running benchmark:

 % bencher ... --show-items-results

Select (include/exclude) participants before running benchmark (you can also
select datasets/modules/items):

 % bencher ... --include-participant-pattern 'Tiny|Lite' --exclude-participant 'HTTP::Tiny'

=head2 Benchmarking against multiple perls

You need to install L<App::perlbrew> first and then install some perls. Also,
install at least L<Bencher::Backend> to each perl you want to run the benchmark
on.

To list available perls (same as C<perlbrew list>, but also shows whether a perl
has Bencher):

 % bencher --list-perls
 % bencher --list-perls -l

To run a scenario against all perls which have Bencher:

 % bencher -m ScenarioModule --multiperl ...

To run a scenario against some perls:

 % bencher -m ScenarioModule --multiperl --include-perl perl-5.20.3 --include-perl perl-5.22.1 ...

=head2 Benchmarking multiple versions of a module

For example, if version 0.02 of a module is installed and you want to benchmark
against version 0.01 (in C</my/home/lib>):

 % bencher -m ScenarioModule --multimodver Module::Name -I /my/home/lib ...

Note that C<Module::Name> must be among the modules that are being benchmarked
(according to the scenario).


=head1 append:ENVIRONMENT

=head2 BENCHER_RESULT_DIR => str

Set default for C<--results-dir>.
